# make sure you're logged in with `huggingface-cli login`
import os
import shutil
import time
import uuid
from dataclasses import dataclass, field

import gradio as gr
import numpy as np
import PIL
import torch
from diffusers import (
    AutoencoderKL,
    DiffusionPipeline,
    DPMSolverMultistepScheduler,
    PNDMScheduler,
    StableDiffusionImageVariationPipeline,
    StableDiffusionInpaintPipeline,
    StableDiffusionPipeline,
    UNet2DConditionModel,
)
from diffusers.utils import floats_tensor, load_image, load_numpy, torch_device
from PIL import Image
from torchvision import transforms

import cli
import constants
import models


class StableDiffusionConfig:
    """
    A class that wraps the Stable Diffusion models from Hugging Face with configuration options.
    """

    def __init__(
        self,
        pipeline: DiffusionPipeline = StableDiffusionPipeline,
        repo_name: str = "runwayml/stable-diffusion-v1-5",
        title: str = None,
        scheduler: bool = False,
        pipeline_options: dict = None,
    ) -> None:
        """
           Initialize the Stable Diffusion class with the pipeline, repo_name, and title values.
        Args:
            pipeline: one of StableDiffusionPipeline or DiffusionPipeline
            repo_name: The name of the repo to load the model from
            title: The type of stable diffusion model to load
            scheduler: Whether to use the scheduler or not
        """
        self.title = title
        self.pipe = (
            pipeline.from_pretrained(repo_name, **pipeline_options)
            if pipeline_options
            else pipeline.from_pretrained(repo_name)
        )
        self.pipe = self.pipe.to("mps")
        self.pipe.enable_attention_slicing()
        if scheduler:
            self.pipe.scheduler = DPMSolverMultistepScheduler.from_config(
                pipe.scheduler.config
            )

    def txt2img(self, prompt: str, **options: dict):
        """
        Convert text to an image using the Stable Diffusion model.
        Args:
            prompt: The text to convert to an image
            **options:
                num_inference_steps: The number of inference steps to take
                guidance_scale: The scale of the guidance
        Returns:
            The image generated by the model.
        """
        return self.pipe(prompt, **options).images[0]

    def img2img(self, prompt: PIL.Image, **options: dict):
        """
        Convert an image to an image using the Stable Diffusion model.
        Args:
            prompt: The image to convert to an image
            **options:
                num_inference_steps: The number of inference steps to take
                guidance_scale: The scale of the guidance
        Returns:
            The image generated by the model.
        """
        return self.pipe(prompt, **options).images[0]


def queued_txt2img(prompt, model, save_path, filename):
    """
    Convert text to an image using the Stable Diffusion model.
    Args:
        prompt: The text to convert to an image
        model: The model to use
        save_path: The path to save the image to
    Returns:
        The image generated by the model.
    """
    try:
        static_image_job(prompt, model, save_path, filename)
    except Exception as e:
        print(e)
        print("failed job")
        return "failed"


def static_image_job(prompt, model, save_path, filename):
    # check what options the model has
    options = {}
    if hasattr(model, "num_inference_steps"):
        options["num_inference_steps"] = model.num_inference_steps
    if hasattr(model, "guidance_scale"):
        options["guidance_scale"] = model.guidance_scale
    cls = model.__class__
    print("starting job")
    print(f"Checking if file exists first: {save_path}/{filename}")
    concat_path = os.path.join(save_path, filename)
    if os.path.exists(concat_path):
        print(f"{concat_path} exists")
        print(f"Job finished for {prompt}")
        return
    if not os.path.exists(save_path):
        os.mkdir(save_path)
    img = cls.pipe(prompt, **options).images[0]
    print("finished job")
    img.save(concat_path)
    print(f"image saved to {concat_path}")


def generate_all_models(**options):
    """
    Generate images with the Stable Diffusion models.
    Returns:
        None
    """
    # times = []
    for cls in models.DEFAULT_MODELS:
        try:
            start_time = time.time()
            total_time = make_image(cls)
            # times.append({"model": cls.__name__, "time": total_time})
            end_time = time.time()
            total_time = end_time - start_time
            # times.append({"model": cls.__name__, "time": total_time})
        except Exception as e:
            if options.get("verbose", True):
                print(e)
            if options.get("speech", True):
                os.system(f"say '{cls.__name__} failed'")
    if options.get("speech", True):
        os.system("say 'jobs done'")
    # sort times by fastest to slowest
    # times = sorted(times, key=lambda x: x["time"])
    # if options.get("verbose", True):
    #     print(times)


def make_image(
    cls, image_class, regenerate_prompt=None, verbosity=True, speech=True, **kwargs
):
    """
    Generate an image with the Stable Diffusion model and save it to the output folder.
    Args:
        cls: The Stable Diffusion model class
        image_class: The image object with stateful information regarding file paths and prompts
        verbosity: Whether to print steps to the console
        speech: Whether to use the speech synthesizer to say the model name
        regenerate_prompt: Whether to regenerate the image if it already exists and use a different prompt
    """
    # check if the image has already been generated
    render_count = 0
    re_render = False
    if regenerate_prompt:
        re_render = True
    while render_count < 5:
        if not regenerate_prompt and not re_render:
            for image in image_class.saved_images:
                if cls.title in image:
                    if verbosity:
                        print(f"Image with {cls.title} already exists")
                    return
            if verbosity:
                print(f"Generating image with {cls.title}")
        prompt = regenerate_prompt or image_class.prompt_line
        # check if prompt has curly braces anywhere in the string and if not add them to the beginning and end
        if "{" not in prompt and "}" not in prompt:
            prompt = "{" + prompt + "}"

        if kwargs.get("queued"):
            queue.enqueue(
                cls.txt2img,
                prompt=prompt,
                image_class=image_class,
                result_ttl=0,
                job_timeout=600,
                job_id=str(uuid.uuid4()),
            )
            return
        img = cls.txt2img(prompt=prompt)
        save_path = image_class.save_image(cls, img)
        # check if img has been turned all black due to the nsfw filter
        img = PIL.Image.open(save_path)
        if img.getbbox() is not None:
            print(f"Generated image with {cls.title} at {save_path}")
            break
        os.remove(save_path)
        render_count += 1
        print("Image has been turned all black due to nsfw filter")
        print(f"This has happened {render_count} times so far... something is wrong?!")
        re_render = True
    if render_count > 5:
        print(
            f"Image has been turned all black due to nsfw filter {render_count} times"
        )
        print("Skipping image... rethink your prompt")
        return

    if speech:
        os.system(f"say '{cls.title} done'")


@dataclass
class Project:
    """
    A class to hold the project information.
    """

    id: str
    prompt: str = ""
    master_folder: str = "outputs"
    output_folder: str = None
    image_indices: list = field(default_factory=list)
    models: list = field(default_factory=list)

    def __post_init__(self):
        """
        Create the output folder and save the prompt
        """
        self.output_folder = f"{self.master_folder}/{self.id}"
        if not os.path.exists(self.master_folder):
            os.mkdir(self.master_folder)
        if not os.path.exists(self.output_folder):
            os.mkdir(self.output_folder)
        if not os.path.exists(f"{self.output_folder}/prompt.txt"):
            with open(f"{self.output_folder}/prompt.txt", "w") as f:
                f.write(self.prompt)

    def load(self):
        """
        Load a project from the master folder
        """
        self.output_folder = f"{self.master_folder}/{self.id}"
        with open(f"{self.output_folder}/prompt.txt", "r") as f:
            self.prompt = f.read()
        self.models = []
        # scan the image index folders to find each folder name that was created
        for index_folder in os.listdir(self.output_folder):
            if index_folder not in ["prompt.txt", "index.html"]:
                for model in os.listdir(f"{self.output_folder}/{index_folder}"):
                    if model not in self.models:
                        self.models.append(model)
        # models should be a string with StableDiffusion in the front of it
        # filter out any stray folders that may have been created
        self.models = list(filter(lambda x: "StableDiffusion" in x, self.models))
        self.setup_prompt_indices()

    def setup_prompt_indices(self):
        for index, line in enumerate(self.prompt.splitlines()):
            if line:
                image_index = ImageIndex(index=index, project=self, prompt_line=line)
                image_index.add_indexes_folder()
                image_index.add_prompts_file()
                image_index.add_class_folders(self.models)
                for model in self.models:
                    if os.path.exists(
                        f"{image_index.index_folder}/{model}/{index}.png"
                    ):
                        image_index.saved_images.append(
                            f"{image_index.index_folder}/{model}/{index}.png"
                        )
                self.image_indices.append(image_index)

    def models_to_images(self, **kwargs):
        """
        Generate images for each model in the project
        """
        for model in self.models:
            sd_config = self.config_class(model)
            for image_index in self.image_indices:
                print(f"Generating image for line {image_index.index} with {model}")
                make_image(
                    sd_config,
                    image_index,
                    **kwargs,
                )

    @staticmethod
    def config_class(cls):
        if isinstance(cls, str):
            cls = models.MODEL_STR_TO_CLASS.get(cls, None)
        if isinstance(cls, int):
            cls = models.MODEL_INT_TO_STR.get(cls, None)
        if not cls:
            raise ValueError("Model class not found")
        sd = cls()
        return StableDiffusionConfig(title=cls.__name__, **sd.__dict__)

    async def html_render(self):
        """
        Render an html page with all the images
        """
        html = f"""
        <html>
        <head>
        <style>
        .grid {{
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            grid-gap: 10px;
            grid-auto-rows: minmax(100px, auto);
        }}
        .grid-item {{
            background-color: rgba(255, 255, 255, 0.8);
            border: 1px solid rgba(0, 0, 0, 0.8);
            padding: 20px;
            font-size: 30px;
            text-align: center;
        }}
        </style>
        </head>
        <body>
        <div class="grid">
        """
        absolute_path = "/Users/joshwren/Code/playground/storyboardai/"
        for image_index in self.image_indices:
            for image in image_index.saved_images:
                # this is a local path to a local file on a local machine
                # we need to ensure that localhost is not prepended to the path
                # so that the images can be found
                html += f"""
                <div class="grid-item">
                <h3>{image_index.prompt_line}</h3>
                <img src="{image.replace(absolute_path, "")}" />
                </div>
                """
        html += """
        </div>
        </body>
        </html>
        """
        with open(f"templates/projects/{self.id}.html", "w") as f:
            f.write(html)


@dataclass
class ImageIndex:
    index: int
    project: Project
    prompt_line: str
    index_folder: str = None
    prompt_file: str = None
    class_folders: list = field(default_factory=list)
    saved_images: list = field(default_factory=list)

    def add_indexes_folder(self):
        """
        Add a folder for the index
        """
        index_folder = f"{self.project.output_folder}/{self.index}"
        if not os.path.exists(index_folder):
            os.mkdir(index_folder)
        if os.path.exists(index_folder):
            self.index_folder = index_folder
        else:
            raise ValueError("index_folder failed to be created")

    def add_prompts_file(self):
        """
        Add a file for the prompt
        """
        if self.index_folder is None:
            raise ValueError("index_folder must be set")
        prompt_file = f"{self.index_folder}/{self.index}_prompt.txt"
        with open(prompt_file, "w") as f:
            f.write(self.prompt_line)
        if not os.path.exists(prompt_file):
            raise ValueError("prompt_file failed to be created")
        self.prompt_file = prompt_file

    def add_class_folders(self, classes: list[str]):
        """
        Add a folder for the class
        classes: a list of classes to add folders for
        """
        if self.index_folder is None:
            raise ValueError("index_folder must be set")
        for cls in classes:
            class_folder = None
            if isinstance(cls, str):
                class_folder = f"{self.index_folder}/{cls}"
            if isinstance(cls, int):
                class_folder = f"{self.index_folder}/{models.MODEL_INT_TO_STR[cls]}"
            if type(cls) not in [str, int]:
                class_folder = f"{self.index_folder}/{cls.__name__}"
            if not os.path.exists(class_folder):
                os.mkdir(class_folder)
            if os.path.exists(class_folder):
                self.class_folders.append(class_folder)
            else:
                raise ValueError("class_folder failed to be created")

    def save_image(self, sd_model: str, img: PIL.Image):
        """
        Create a filename and path for the image
        """
        save_path = f"{self.index_folder}/{sd_model.title}/{self.index}.png"
        img.save(save_path)
        if not os.path.exists(save_path):
            raise ValueError("save_path failed to be created")
        self.saved_images.append(save_path)
        return save_path


def batch_generate_images(
    prompt_path: str = "input/prison_full.txt", models: list = None
):
    """
    Generate A batch of images for each line of the prompt
    """
    with open(prompt_path, "r") as f:
        prompt = f.read()
    if models is None:
        models = models.DEFAULT_MODELS
    new_project = Project(id=str(uuid.uuid4()), prompt=prompt, models=models)
    new_project.setup_prompt_indices()
    new_project.models_to_images()


def resume_batch_images(id: str, **kwargs):
    """
    Resume a batch of images for each line of the prompt
    """
    project = Project(id=id)
    project.load()
    project.models_to_images(**kwargs)


def from_single_prompt(incoming_prompt: str = None):
    """
    Generate A batch of images for each line break of the prompt
    """

    prompt = incoming_prompt or input("Enter prompt: ")
    prompt = " {{" + prompt + "}} "  # this emphasizes the prompt for stable diffusion
    prefix = cli.ask_for_random(
        "prefix", constants.PROMPT_PREFIX_IDEAS, current_prompt=prompt
    )

    prompt = prefix + prompt

    suffix = cli.ask_for_random(
        "suffix", constants.PROMPT_SUFFIX_IDEAS, current_prompt=prompt
    )

    prompt = prompt + suffix

    new_project = Project(
        id=str(uuid.uuid4()), prompt=prompt, models=models.DEFAULT_MODELS
    )
    new_project.setup_prompt_indices()
    new_project.models_to_images()


def delete_filtered_images(project_id: str):
    """
    Scan a projects image files for any images that have been filtered by nsfw filter and delete them
    Filtered images are all black
    """
    breakpoint()
    project = Project(id=project_id)
    project.load()
    for image_index in project.image_indices:
        for saved_image in image_index.saved_images:
            img = PIL.Image.open(saved_image)
            if img.getbbox() is None:
                print(f"Deleting {saved_image}")
                os.remove(saved_image)
            else:
                print(f"Keeping {saved_image}")


def regenerate_image(
    project_id: str,
    index: int,
    model: str,
    prompt_prefix: str = None,
    prompt_suffix: str = None,
):
    """
    Regenerate a single image
    """
    project = Project(id=project_id)
    project.load()
    image_index = project.image_indices[index]
    sd_config = project.config_class(model)
    current_prompt = image_index.prompt_line
    # add curly braces to the prompt to emphasize it for stable diffusion
    current_prompt = " {{" + current_prompt + "}} "
    if prompt_prefix:
        current_prompt = f"{prompt_prefix} {current_prompt}"
    if prompt_suffix:
        current_prompt = f"{current_prompt} {prompt_suffix}"
    # make copies of the current images
    backup_folder = f"{image_index.index_folder}/backup"
    backup_index = 0
    backed_up = False
    while not backed_up:
        backup_folder = f"{backup_folder}_{backup_index}"
        if not os.path.exists(backup_folder):
            os.mkdir(backup_folder)
            backed_up = True
        else:
            backup_index += 1
    for saved_image in image_index.saved_images:
        # find the model name in the saved image path
        model_name = saved_image.split("/")[-2]
        os.mkdir(f"{backup_folder}/{model_name}")
        shutil.copy(saved_image, f"{backup_folder}/{model_name}")
    # make new prompt txt file in the folder of the model being regenerated
    prompt_file = f"{image_index.index_folder}/{sd_config.title}/{image_index.index}_prompt_regen.txt"
    with open(prompt_file, "w") as f:
        f.write(current_prompt)
    make_image(sd_config, image_index, regenerate_prompt=current_prompt)


def paginated_images(
    page: int, page_size: int, project_id: str, model_filter: str = None
):
    """
    Get a paginated list of images for a projects
    """
    project = Project(id=project_id)
    project.load()
    image_indices = project.image_indices
    start = page * page_size
    end = start + page_size
    if not model_filter:
        return image_indices[start:end]
    # only return images that have an image file in a
    # folder with the model_filter name for the given indices
    filtered_indices = []
    for image_index in image_indices[start:end]:
        for saved_image in image_index.saved_images:
            # example of saved_image path:
            # 'outputs/33527d88-636b-4833-876d-6d0665d970b5/9/StableDiffusionV1/9.png'
            # we want to check if StableDiffusionV1 is in the path but not match StableDiffusionV1Base
            saved_images_model = saved_image.split("/")[-2]
            if model_filter != saved_images_model:
                print(f"model_filter {model_filter} not in {saved_images_model}")
            else:
                filtered_indices.append(saved_image)
    return filtered_indices


def print_image(image_path: str):
    """
    Print an image to the console
    """
    img = PIL.Image.open(image_path)
    img.show()


def img2img(
    input_im,
    scale=3.0,
    n_samples=4,
    steps=25,
    seed=0,
):
    device = "cuda" if torch.cuda.is_available() else "mps"
    pipe = StableDiffusionImageVariationPipeline.from_pretrained(
        "lambdalabs/sd-image-variations-diffusers", safety_checker=None
    )
    pipe = pipe.to(device)
    generator = torch.Generator(device="mps").manual_seed(int(seed))

    tform = transforms.Compose(
        [
            transforms.ToTensor(),
            transforms.Resize(
                (224, 224),
                interpolation=transforms.InterpolationMode.BICUBIC,
                antialias=False,
            ),
            transforms.Normalize(
                [0.48145466, 0.4578275, 0.40821073],
                [0.26862954, 0.26130258, 0.27577711],
            ),
        ]
    )
    inp = tform(input_im).to(device)

    images_list = pipe(
        inp.tile(n_samples, 1, 1, 1),
        guidance_scale=scale,
        num_inference_steps=steps,
        generator=generator,
    )

    return [image for image in images_list["images"]]


import random


def generation_loss(pic="../nathan.jpg", set_seed=None):
    """
    Generate images from a given image and from that one continually until told to stop
    :param pic: the path to the image to generate from
    :return:
    """

    title = pic.split("/")[-1].split(".")[0]
    index = 2
    Image.open(pic).show()
    while True:
        seed = set_seed or random.randint(0, 100000)
        image_output = img2img(
            input_im=Image.open(pic),
            scale=3.0,
            n_samples=1,
            steps=25,
            seed=seed,
        )
        pic = f"../{title}_gen_{index}.png"
        image_output[0].save(pic)
        image_output[0].show()
        cont = input("Continue? (y/n)")
        index += 1
        if cont == "n":
            break


def img_inpainting(img, prompt):
    """
    Change an image based on the prompt
    """
    model_id = "stabilityai/stable-diffusion-2-inpainting"
    pipe = StableDiffusionInpaintPipeline.from_pretrained(model_id, safety_checker=None)
    pipe.to("mps")
    pipe.set_progress_bar_config(disable=None)
    pipe.enable_attention_slicing()

    # init_image = load_image(
    #     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main"
    #     "/sd2-inpaint/init_image.png"
    # )
    # mask_image = load_image(
    #     "https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd2-inpaint/mask.png"
    # )
    # find the foreground of the init image

    img_foreground = img.convert("L").point(lambda x: 0 if x < 128 else 255, mode="1")

    # # convert init_image to a tensor
    # init_image = transforms.ToTensor()(init_image)
    # # convert img_foreground to a tensor of the same size as init_image
    # img_foreground = transforms.ToTensor()(img_foreground).resize(
    #     init_image.shape[1], init_image.shape[2]
    # )

    # prompt = "Face of a yellow cat, high resolution, sitting on a park bench"

    generator = torch.manual_seed(0)
    output = pipe(
        prompt=prompt,
        image=img,
        mask_image=img_foreground,
        generator=generator,
    )
    return output.images[0]


if __name__ == "__main__":
    img_inpainting(Image.open("../nathan.jpg"), "more muscular").show()
